{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a233a33-71c4-460b-8523-d95303dd6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#pip install torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "#https://pytorch.org/docs/stable/torchvision/index.html\n",
    "import imageio\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "937aabdd-da00-4adf-b83e-6f6cf5706813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './flower_data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "valid_dir = data_dir + 'valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8559884-4b59-4918-98cd-c025c84254a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae70838-13e6-46d1-b1a7-8f597c4d8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize([96,96]),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.RandomGrayscale(p=0.025),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])       \n",
    "    ]),\n",
    "    'valid':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize([64,64]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "        \n",
    "        ])  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22539696-d606-4d9e-8f76-ed2575ee4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e4bd873-fba9-4d78-ad24-bde62860ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_datasets = {'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
    "                 'valid': datasets.ImageFolder(valid_dir, data_transforms['valid'])\n",
    "                 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5441d0-b286-401b-87d7-1aaba339658c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a83ecc2a-c396-4bff-b541-c6261779ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d4c8503-32e4-4e72-a096-3fb49e95255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size = batch_size, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size = batch_size)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(image_datasets['train']),\n",
    "    'valid': len(image_datasets['valid'])\n",
    "}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dac4c01c-c7fb-4374-b840-ab0e57034344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b8f2eb6-d4f0-4379-922b-21270c0b6763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x2df03fdc0>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x2df03f2e0>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b23f4863-ec43-49f6-9b01-846c122c260d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 6552, 'valid': 818}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5053e3e-e26e-4f31-8779-9c19e3e51684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the actual label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bd0158c-5ffa-4123-9415-0d86e3835a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e065dc17-b0b7-4760-aa4e-061bd724b140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21': 'fire lily',\n",
       " '3': 'canterbury bells',\n",
       " '45': 'bolero deep blue',\n",
       " '1': 'pink primrose',\n",
       " '34': 'mexican aster',\n",
       " '27': 'prince of wales feathers',\n",
       " '7': 'moon orchid',\n",
       " '16': 'globe-flower',\n",
       " '25': 'grape hyacinth',\n",
       " '26': 'corn poppy',\n",
       " '79': 'toad lily',\n",
       " '39': 'siam tulip',\n",
       " '24': 'red ginger',\n",
       " '67': 'spring crocus',\n",
       " '35': 'alpine sea holly',\n",
       " '32': 'garden phlox',\n",
       " '10': 'globe thistle',\n",
       " '6': 'tiger lily',\n",
       " '93': 'ball moss',\n",
       " '33': 'love in the mist',\n",
       " '9': 'monkshood',\n",
       " '102': 'blackberry lily',\n",
       " '14': 'spear thistle',\n",
       " '19': 'balloon flower',\n",
       " '100': 'blanket flower',\n",
       " '13': 'king protea',\n",
       " '49': 'oxeye daisy',\n",
       " '15': 'yellow iris',\n",
       " '61': 'cautleya spicata',\n",
       " '31': 'carnation',\n",
       " '64': 'silverbush',\n",
       " '68': 'bearded iris',\n",
       " '63': 'black-eyed susan',\n",
       " '69': 'windflower',\n",
       " '62': 'japanese anemone',\n",
       " '20': 'giant white arum lily',\n",
       " '38': 'great masterwort',\n",
       " '4': 'sweet pea',\n",
       " '86': 'tree mallow',\n",
       " '101': 'trumpet creeper',\n",
       " '42': 'daffodil',\n",
       " '22': 'pincushion flower',\n",
       " '2': 'hard-leaved pocket orchid',\n",
       " '54': 'sunflower',\n",
       " '66': 'osteospermum',\n",
       " '70': 'tree poppy',\n",
       " '85': 'desert-rose',\n",
       " '99': 'bromelia',\n",
       " '87': 'magnolia',\n",
       " '5': 'english marigold',\n",
       " '92': 'bee balm',\n",
       " '28': 'stemless gentian',\n",
       " '97': 'mallow',\n",
       " '57': 'gaura',\n",
       " '40': 'lenten rose',\n",
       " '47': 'marigold',\n",
       " '59': 'orange dahlia',\n",
       " '48': 'buttercup',\n",
       " '55': 'pelargonium',\n",
       " '36': 'ruby-lipped cattleya',\n",
       " '91': 'hippeastrum',\n",
       " '29': 'artichoke',\n",
       " '71': 'gazania',\n",
       " '90': 'canna lily',\n",
       " '18': 'peruvian lily',\n",
       " '98': 'mexican petunia',\n",
       " '8': 'bird of paradise',\n",
       " '30': 'sweet william',\n",
       " '17': 'purple coneflower',\n",
       " '52': 'wild pansy',\n",
       " '84': 'columbine',\n",
       " '12': \"colt's foot\",\n",
       " '11': 'snapdragon',\n",
       " '96': 'camellia',\n",
       " '23': 'fritillary',\n",
       " '50': 'common dandelion',\n",
       " '44': 'poinsettia',\n",
       " '53': 'primula',\n",
       " '72': 'azalea',\n",
       " '65': 'californian poppy',\n",
       " '80': 'anthurium',\n",
       " '76': 'morning glory',\n",
       " '37': 'cape flower',\n",
       " '56': 'bishop of llandaff',\n",
       " '60': 'pink-yellow dahlia',\n",
       " '82': 'clematis',\n",
       " '58': 'geranium',\n",
       " '75': 'thorn apple',\n",
       " '41': 'barbeton daisy',\n",
       " '95': 'bougainvillea',\n",
       " '43': 'sword lily',\n",
       " '83': 'hibiscus',\n",
       " '78': 'lotus lotus',\n",
       " '88': 'cyclamen',\n",
       " '94': 'foxglove',\n",
       " '81': 'frangipani',\n",
       " '74': 'rose',\n",
       " '89': 'watercress',\n",
       " '73': 'water lily',\n",
       " '46': 'wallflower',\n",
       " '77': 'passion flower',\n",
       " '51': 'petunia'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81a6e08d-84cf-4e0e-9909-91321060ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1c4bef6-d778-42da-8d35-9acac0786719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet'\n",
    "feature_extract = True # 使用pretrained model的特征和参数，暂时不训练，不进行gradient decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8adfb1bb-3e25-4bdb-a694-a882b2ce3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "mps is available, training on GPU...\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.backends.mps.is_available()\n",
    "print(train_on_gpu)\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('mps is not available, training on CPU...')\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print('mps is available, training on GPU...')\n",
    "    device = torch.device('mps')\n",
    "    \n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1d71db2-ed1e-4270-b743-a036240aaed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "model = models.resnet18()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5300df64-0f85-46bb-a222-55e23a2dcaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model, num_classes, feature_extract, use_pretrained = True):\n",
    "    model = models.resnet18(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    \n",
    "    num_features_into_fc = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features_into_fc, 102) #output 102 classes\n",
    "    \n",
    "    input_size = 64\n",
    "    \n",
    "    return model, input_size\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcd774-e738-4226-996f-6d006d9a4ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62c57d89-3108-48a0-a00c-bfe0f847e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fclassifier, input_size = initialize_model(model, 102, feature_extract, use_pretrained = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdb127-4047-4146-be89-fed95914d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fclassifier = model_fclassifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f9e30-6116-4cbe-8b21-fcdbf78006de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to train/learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# model save\n",
    "filename = 'check.pth'\n",
    "# not_train all layers, only train fc layers\n",
    "params_to_train = model_fclassifier.parameters()\n",
    "\n",
    "print('Params to train/learn:')\n",
    "if feature_extract:\n",
    "    params_to_train = []\n",
    "    for name, param in model_fclassifier.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_train.append(param)\n",
    "            print('\\t', name)\n",
    "else:\n",
    "    for name, param in model_fclassifier.names_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print('\\t', name)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bf012-e148-4cb8-a638-583fc47f5f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0327,  0.0168, -0.0202,  ...,  0.0415,  0.0049, -0.0282],\n",
       "         [-0.0014,  0.0166,  0.0212,  ...,  0.0406,  0.0370,  0.0105],\n",
       "         [-0.0409, -0.0031,  0.0380,  ...,  0.0421, -0.0127, -0.0154],\n",
       "         ...,\n",
       "         [-0.0043, -0.0197, -0.0171,  ...,  0.0207, -0.0398, -0.0125],\n",
       "         [ 0.0123,  0.0272,  0.0323,  ..., -0.0017, -0.0306, -0.0127],\n",
       "         [-0.0306,  0.0321,  0.0408,  ...,  0.0008,  0.0348,  0.0297]],\n",
       "        device='mps:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0110, -0.0072, -0.0154,  0.0198,  0.0162,  0.0313,  0.0273, -0.0364,\n",
       "         -0.0353, -0.0251, -0.0211,  0.0083, -0.0100,  0.0410, -0.0003, -0.0195,\n",
       "         -0.0156, -0.0260, -0.0107, -0.0340, -0.0293, -0.0343,  0.0267, -0.0396,\n",
       "          0.0144,  0.0359, -0.0051, -0.0102,  0.0043,  0.0044, -0.0125,  0.0311,\n",
       "         -0.0007, -0.0428, -0.0291,  0.0404,  0.0395,  0.0056,  0.0169, -0.0194,\n",
       "          0.0439,  0.0051,  0.0392,  0.0173, -0.0146, -0.0163, -0.0261,  0.0282,\n",
       "         -0.0186, -0.0207,  0.0358, -0.0006,  0.0188, -0.0022,  0.0156, -0.0381,\n",
       "          0.0173,  0.0272,  0.0254, -0.0066, -0.0361,  0.0283,  0.0380,  0.0143,\n",
       "         -0.0153, -0.0123,  0.0397, -0.0386, -0.0157, -0.0304, -0.0311, -0.0084,\n",
       "          0.0374, -0.0229, -0.0076,  0.0311, -0.0104,  0.0252,  0.0433,  0.0075,\n",
       "          0.0072, -0.0011, -0.0390, -0.0077, -0.0240,  0.0084,  0.0258,  0.0165,\n",
       "         -0.0182,  0.0042,  0.0419,  0.0228,  0.0299,  0.0310,  0.0009, -0.0416,\n",
       "         -0.0042, -0.0119, -0.0198, -0.0050, -0.0068, -0.0364], device='mps:0',\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_train # the parameters need train is fc layer(weight and bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26808cc4-9e12-44e8-89d3-ee41847f47ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041da10-5e41-4ef7-b7c1-19afe39bd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcd127-4fd1-4944-a88e-b51b454af19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params_to_train, lr = 1e-2)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma = 0.1)\n",
    "# learning rate decrease to 1/10 every 10 steps\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec4d14-db3e-46bc-bcde-8e8ad3e817cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, loss_func, optimizer, steps=30, file_name = './check.pth'):\n",
    "    # time calculate\n",
    "    since = time.time()\n",
    "    # record the best acc\n",
    "    best_acc = 0\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    LRs = [optimizer.param_groups[0]['lr']]\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(steps):\n",
    "        print(f'{epoch+1}/{steps}  ')\n",
    "        \n",
    "        # train and valid\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            loss_sum = 0\n",
    "            corrects_sum = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad() # clear the gradient\n",
    "                pred_outputs = model(inputs)\n",
    "                loss = loss_func(pred_outputs, labels)\n",
    "                _, preds = torch.max(pred_outputs, 1)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                loss_sum += loss.item() * inputs.size(0)\n",
    "                corrects_sum += torch.sum(preds == labels).item()\n",
    "            \n",
    "            epoch_loss = loss_sum / len(dataloaders[phase].dataset) # average loss for each data point\n",
    "            epoch_acc = corrects_sum / len(dataloaders[phase].dataset) # accuracy for one epoch\n",
    "            \n",
    "            time_elasped = time.time() - since\n",
    "            print(f'duration: {round(time_elasped//60,2)} min {round(time_elasped%60,2)}s')\n",
    "            print(f'loss: {round(epoch_loss,2)}, accuracy: {round(epoch_acc,2)}')\n",
    "            \n",
    "            # find the best model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "                \n",
    "                }\n",
    "                torch.save(state, filename)\n",
    "            \n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_losses.append(epoch_loss)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_losses.append(epoch_loss)\n",
    "                \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Optimzer learning rate: {current_lr}')\n",
    "        LRs.append(current_lr)\n",
    "        scheduler.step() # learning rate\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time()-since\n",
    "    print(f'Training complete in {round(time_elapsed//60,2)}min {round(time_elapsed%60,2)}s ')\n",
    "    print(f'Best val accuracy: {round(best_acc,2)}')\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_acc_history, val_acc_history, train_losses, val_losses, LRs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a8ebb-1559-4723-8d62-0be6d82a8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/15  \n",
      "duration: 0.0 min 23.16s\n",
      "loss: 3.9, accuracy: 0.25\n",
      "duration: 0.0 min 25.55s\n",
      "loss: 3.64, accuracy: 0.29\n",
      "Optimzer learning rate: 0.01\n",
      "2/15  \n",
      "duration: 0.0 min 48.52s\n",
      "loss: 2.85, accuracy: 0.4\n",
      "duration: 0.0 min 50.92s\n",
      "loss: 3.44, accuracy: 0.31\n",
      "Optimzer learning rate: 0.01\n",
      "3/15  \n",
      "duration: 1.0 min 13.92s\n",
      "loss: 2.78, accuracy: 0.41\n",
      "duration: 1.0 min 16.29s\n",
      "loss: 3.55, accuracy: 0.31\n",
      "Optimzer learning rate: 0.01\n",
      "4/15  \n"
     ]
    }
   ],
   "source": [
    "train(model_fclassifier, dataloaders, loss_func, optimizer, steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d3c8e-abef-411c-a15f-eaba72f19d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf6111-9b43-4048-a237-52c22d87282f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886942d-569f-453a-8536-bf88e060309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_fclassifier.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eca7ca-87c5-4c15-b217-b3571243c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1,2,3,4])\n",
    "t2 = torch.tensor([1,2,1,1])\n",
    "torch.sum(t1 == t2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f24a0-e9cc-476f-9732-f64a9364b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c37112-6326-41a0-8ff4-f8b4cb724c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed57952-9f23-42fd-88e0-7627ec5bd1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d54f5-9d0d-44af-9b97-09245eb17a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfbf35-34c2-41a4-bb3e-815c49b68028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10054a8-b76a-43e4-89cd-479ace85e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
